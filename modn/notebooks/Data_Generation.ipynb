{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Q1WA2ejbAr7L",
        "EbUznxfbYls4",
        "fhGh0pk3FdoB",
        "MzUjBXB9oFwP"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "-1gjK-EW8sDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bF6Cd5vwf04",
        "outputId": "c84c22b6-d36a-4149-b525-1e36ef8f3b9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import minimize\n",
        "import statistics"
      ],
      "metadata": {
        "id": "oIaNb595wgV2"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set datasets timesteps and time series name\n",
        "dataset_info = {'mimic': {'ts': 48,\n",
        "                          'features': ['WBC', 'Chloride (serum)', 'Glucose (serum)']#, 'Magnesium', 'Sodium (serum)', 'BUN',\n",
        "                            #   'Phosphorous', 'Anion gap', 'Potassium (serum)', 'HCO3 (serum)', 'Platelet Count',\n",
        "                            #   'Prothrombin time', 'PTT', 'Lactic Acid']\n",
        "                          },\n",
        "                'toy': {'ts': 10,\n",
        "                        'features': ['F1_constant', 'F2_early', 'F3_late', 'F4_narrow', 'F5_wide']\n",
        "                        }\n",
        "}"
      ],
      "metadata": {
        "id": "G4_Nj-8MN82f"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Toy Dataset"
      ],
      "metadata": {
        "id": "Q1WA2ejbAr7L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parameters and variables"
      ],
      "metadata": {
        "id": "EZ9pkBTjxf0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Output path for the toy dataset\n",
        "output_path_toy = \"/content/drive/MyDrive/OptionalProject/MIMIC_data_labels_toy.csv\"\n",
        "\n",
        "# Number of timesteps in the timeseries\n",
        "TIMESTEPS = 10\n",
        "# Number of patients to generate\n",
        "RECORDS = 1\n",
        "# Show timeseries plots when generating\n",
        "VERBOSE = True\n",
        "\n",
        "# Define the static features and the label\n",
        "label = ['0', '1']\n",
        "gender_values = ['M', 'F']\n",
        "age_values = list(range(18, 99, 1))\n",
        "insurance_values = ['Other', 'Medicare', 'Medicaid']\n",
        "\n",
        "static_feat = ['gender', 'Age', 'insurance', 'label']\n",
        "\n",
        "\n",
        "# Define continuous features\n",
        "cont_feat = ['F1_constant', 'F2_early', 'F3_late', 'F4_narrow', 'F5_wide']"
      ],
      "metadata": {
        "id": "sAtZpiz1xkSf"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper funtions"
      ],
      "metadata": {
        "id": "E6_zGZKGxSJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_function(x, a, b):\n",
        "    return 1 / (1 + np.exp(-(a * x + b)))\n",
        "\n",
        "\n",
        "def generate_y(early=True):\n",
        "    # TODO: Make this dependent on the timesteps, not fixed\n",
        "\n",
        "    data = np.array([0, 0, 0, 0, 0.3, 0.5, 0.7, 1, 1, 1])\n",
        "    assert len(data) == TIMESTEPS, 'Change length of y_data'\n",
        "\n",
        "    if early:\n",
        "        y_data = data\n",
        "    else:\n",
        "        y_data = 1 - data\n",
        "\n",
        "    return y_data\n",
        "\n",
        "\n",
        "def show(x_data, y_data, y_constant, axes, title):\n",
        "\n",
        "    # Plot the points and logistic function\n",
        "    if title == 'Constant':\n",
        "        axes.scatter(x_data, y_data, color='red', label='Data Points')\n",
        "    else:\n",
        "        axes.scatter(x_data, y_data, color='red')\n",
        "\n",
        "    axes.scatter(x_data, y_constant, color='red')\n",
        "    if title == 'Constant':\n",
        "        axes.plot(x_data, y_data, color='blue', label='Label_1')\n",
        "        axes.plot(x_data, y_constant, color='green', label='Label_0')\n",
        "    else:\n",
        "        axes.plot(x_data, y_data, color='blue')\n",
        "        axes.plot(x_data, y_constant, color='green')\n",
        "\n",
        "    if title == 'Constant':\n",
        "        axes.legend(fontsize=\"8\", loc=\"best\")\n",
        "\n",
        "    axes.set_title(title)\n",
        "    axes.set_xlabel('x')\n",
        "    axes.set_ylabel('y')\n",
        "\n",
        "\n",
        "def generate_continuous_function(early, axes, title, verbose=False):\n",
        "\n",
        "    # Define the points\n",
        "    x_data = np.array(range(0, TIMESTEPS))\n",
        "    y_data = generate_y(early)\n",
        "\n",
        "    def loss_function(params):\n",
        "        a, b = params\n",
        "        y_pred = logistic_function(x_data, a, b)\n",
        "        loss = -np.mean(y_data * np.log(y_pred) + (1 - y_data) * np.log(1 - y_pred))\n",
        "        return loss\n",
        "\n",
        "    # Perform logistic regression using minimize\n",
        "    initial_params = np.zeros(2)  # Initial guess for parameters\n",
        "    result = minimize(loss_function, initial_params, method='SLSQP')\n",
        "\n",
        "    # Retrieve the optimized parameters\n",
        "    params = result.x\n",
        "\n",
        "    # Generate points to plot the logistic function\n",
        "    y_data = logistic_function(x_data, params[0], params[1])\n",
        "\n",
        "    x_coord = np.random.uniform(low=-2.0, high=2.0, size=None)\n",
        "    y_data += x_coord\n",
        "    y_constant = np.full(TIMESTEPS, min(y_data))\n",
        "\n",
        "    if verbose:\n",
        "        show(x_data, y_data, y_constant, axes, title)\n",
        "\n",
        "    return y_constant, y_data\n",
        "\n",
        "\n",
        "def constant_function(verbose, gender, axes, title):\n",
        "\n",
        "    if gender == 'M':\n",
        "        m = np.random.uniform(low=0, high=0.5, size=None)\n",
        "    else:\n",
        "        m = np.random.uniform(low=1.5, high=2, size=None)\n",
        "\n",
        "    x_data = np.array(range(0, TIMESTEPS, 1))\n",
        "    y_data = m * x_data\n",
        "\n",
        "    if gender == 'M':\n",
        "        x_coord = np.random.uniform(low=-2.0, high=0, size=None)\n",
        "    else:\n",
        "        x_coord = np.random.uniform(low=0, high=2.0, size=None)\n",
        "\n",
        "    y_data += x_coord\n",
        "    y_constant = np.full(TIMESTEPS, min(y_data))\n",
        "\n",
        "    if verbose:\n",
        "        show(x_data, y_data, y_constant, axes, title)\n",
        "\n",
        "    return y_constant, y_data\n",
        "\n",
        "\n",
        "def early_late_function(early, axes, title, verbose):\n",
        "\n",
        "    var0, var1 = generate_continuous_function(early, axes, title, verbose)\n",
        "    return var0, var1\n",
        "\n",
        "\n",
        "def wave_function(narrow, axes, title, verbose):\n",
        "\n",
        "    resolution = TIMESTEPS * 2 # how many datapoints to generate\n",
        "    x_data = np.array(range(0, resolution, 1))\n",
        "\n",
        "    cycles = 4 if narrow else 2\n",
        "\n",
        "    length = np.pi * 2 * cycles\n",
        "    y_data = np.sin(np.arange(0, length, length / resolution))\n",
        "\n",
        "    x_coord = np.random.uniform(low=-2.0, high=2.0, size=None)\n",
        "    y_data += x_coord\n",
        "    y_constant = np.full(resolution, statistics.median(sorted(y_data)))\n",
        "    start = np.random.choice(TIMESTEPS)\n",
        "    y_constant = y_constant[start: start+TIMESTEPS]\n",
        "    y_data = y_data[start: start+TIMESTEPS]\n",
        "    x_data = x_data[start: start+TIMESTEPS]\n",
        "\n",
        "    if verbose:\n",
        "        show(x_data, y_data, y_constant, axes, title)\n",
        "\n",
        "    return y_constant, y_data\n",
        "\n",
        "\n",
        "def populate_df(n_rows, cont_feat, static_feat, verbose=False):\n",
        "\n",
        "    timesteps = range(TIMESTEPS)\n",
        "    cont_mi = pd.MultiIndex.from_product([timesteps, cont_feat])\n",
        "    timestep = [-1]\n",
        "\n",
        "    mi = cont_mi.append(pd.MultiIndex.from_product([timestep, static_feat]))\n",
        "    df = pd.DataFrame(columns = mi)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(13, 4))\n",
        "\n",
        "    label_index = 0\n",
        "    for idx in range(n_rows):\n",
        "        if idx >= n_rows // 2:\n",
        "            label_index = 1\n",
        "\n",
        "        l = label[label_index]\n",
        "\n",
        "        f2 = early_late_function(True, axes[1], 'Late', verbose)[label_index]\n",
        "        f3 = early_late_function(False, axes[2], 'Early', verbose)[label_index]\n",
        "        f4 = wave_function(True, axes[3], 'Narrow', verbose)[label_index]\n",
        "        f5 = wave_function(False, axes[4], 'Wide', verbose)[label_index]\n",
        "        cont = [f2, f3, f4, f5]\n",
        "\n",
        "        # Create a balanced dataset regarding gender\n",
        "        if idx % 2 == 0:\n",
        "            g = 'M'\n",
        "        else:\n",
        "            g = 'F'\n",
        "        # g = gender_values[np.random.choice(len(gender_values))]\n",
        "\n",
        "        a = age_values[np.random.choice(len(age_values))]\n",
        "        i = insurance_values[np.random.choice(len(insurance_values))]\n",
        "        static = [g, a, i, l]\n",
        "\n",
        "        f1 = constant_function(verbose, g, axes[0], 'Constant')[label_index]\n",
        "        cont.insert(0, f1)\n",
        "\n",
        "        for t in range(TIMESTEPS):\n",
        "            for j in range(len(cont_feat)):\n",
        "                df.loc[idx, (t, cont_feat[j])] = cont[j][t]\n",
        "\n",
        "        for k in range(len(static_feat)):\n",
        "            df.loc[idx, (-1, static_feat[k])] = static[k]\n",
        "\n",
        "        df[(-1, 'label')] = df[(-1, 'label')].astype(int)\n",
        "\n",
        "        if verbose:\n",
        "            print(\"Gender: {}, Age: {}, Insurance: {}, Label: {}\".format(g, a, i, l))\n",
        "            fig.tight_layout()\n",
        "            fig.show()\n",
        "\n",
        "    df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "pcSxQypIF_al"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creation and saving"
      ],
      "metadata": {
        "id": "zACDr9mfxWwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = populate_df(RECORDS, cont_feat, static_feat, verbose=VERBOSE)\n",
        "# df.to_csv(output_path_toy, index=False)\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "U428Z3qhxL1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot predicted data or generated data"
      ],
      "metadata": {
        "id": "JhWISC67HK0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_generated(df, timesteps, features, nr_patients):\n",
        "\n",
        "    indexes = [str(i) for i in range(1, timesteps)]\n",
        "    cont_df = df.loc[:, pd.IndexSlice[indexes, :]]\n",
        "\n",
        "    for i in range(nr_patients):\n",
        "        fig, ax = plt.subplots(1, len(features), figsize=(15, 4))\n",
        "\n",
        "        # Take labels from timestep 0 to end (on index 0 there is the aggregate label)\n",
        "        label = np.array(df.xs('label', level = 1, axis = 1).loc[i].values[0])\n",
        "        gender = np.array(df.xs('gender', level = 1, axis = 1).loc[i].values[0])\n",
        "\n",
        "        for j, f in enumerate(features):\n",
        "            if len(features) == 1:\n",
        "                pos = ax\n",
        "            else:\n",
        "                pos = ax[j]\n",
        "            y = cont_df.xs(f, level = 1, axis = 1).loc[i].values\n",
        "            x = list(range(1, timesteps))\n",
        "\n",
        "            pos.scatter(np.array(x), np.array(y), color='gray')\n",
        "            pos.plot(x, y, color='red', label='Generated')\n",
        "\n",
        "            pos.set_xlabel('x')\n",
        "            pos.set_ylabel('y')\n",
        "\n",
        "            title = f\n",
        "            if title == 'F2_early':\n",
        "                title = 'F2_late'\n",
        "            if title == 'F3_late':\n",
        "                title = 'F3_early'\n",
        "            pos.set_title(f\"{title}_patient_{i} - {gender}, {label}\")\n",
        "            pos.set_ylim([-4, 4])\n",
        "            pos.set_xticks(range(1, timesteps, 3))\n",
        "            pos.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "def plot_predicted_vs_gt(df, gt_df, timesteps, features, nr_patients):\n",
        "\n",
        "    indexes = [str(i) for i in range(0, timesteps - 1)]\n",
        "    cont_df = df.loc[:, pd.IndexSlice[indexes, :]]\n",
        "    cont_df_gt = gt_df.loc[:, pd.IndexSlice[indexes, :]]\n",
        "\n",
        "    for i in range(nr_patients):\n",
        "        fig, ax = plt.subplots(1, len(features), figsize=(15, 4))\n",
        "\n",
        "        # Take labels from timestep 0 to end (on index 0 there is the aggregated predicted label across timesteps)\n",
        "        label = np.array(df.xs('label', level = 1, axis = 1).loc[i].values[1:])\n",
        "        label_gt = gt_df.xs('label', level = 1, axis = 1).loc[i].values[0]\n",
        "        gender = df.loc[:, ('-1', 'gender')].loc[i]\n",
        "        wrong_idx = np.where(label[:-1] != label_gt)\n",
        "\n",
        "        for j, f in enumerate(features):\n",
        "            if len(features) == 1:\n",
        "                pos = ax\n",
        "            else:\n",
        "                pos = ax[j]\n",
        "            y = cont_df.xs(f, level = 1, axis = 1).loc[i].values\n",
        "            valid_idx = np.argwhere(~np.isnan(y))\n",
        "            y = y[valid_idx]\n",
        "\n",
        "            y_gt = cont_df_gt.xs(f, level = 1, axis = 1).loc[i].values\n",
        "            y_gt = y_gt[valid_idx]\n",
        "\n",
        "            wrong_idx = np.intersect1d(wrong_idx, valid_idx, assume_unique=False)\n",
        "\n",
        "            pos.scatter(np.array(valid_idx), np.array(y), color='red',  label='Predicted')\n",
        "\n",
        "            pos.scatter(np.array(valid_idx), np.array(y_gt), color='green',  label='GT')\n",
        "\n",
        "            # Plot wrong preds\n",
        "            if len(wrong_idx) > 0:\n",
        "                pos.scatter(wrong_idx, np.array(y)[wrong_idx], color='blue', marker = '*', label='Wrong label pred.')\n",
        "                pos.scatter(wrong_idx, np.array(y_gt)[wrong_idx], color='blue', marker = '*')\n",
        "\n",
        "            pos.set_xlabel('x')\n",
        "            pos.set_ylabel('y')\n",
        "\n",
        "            title = f\n",
        "            if title == 'F2_early':\n",
        "                title = 'F2_late'\n",
        "            if title == 'F3_late':\n",
        "                title = 'F3_early'\n",
        "\n",
        "            pos.set_title(f\"{title}_patient_{i} - {gender}, {label_gt}\")\n",
        "            pos.set_ylim([-2.5, 2.5])\n",
        "            pos.set_xticks(range(0, timesteps, 3))\n",
        "            pos.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "fOh8sshnHkX1"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set info for plotting\n",
        "dataset = 'mimic'\n",
        "\n",
        "gt_test_data_path = \"/content/drive/MyDrive/OptionalProject/GT_predicted_data_labelenc_notarget_randominit_small.csv\"\n",
        "pred_data_path = \"/content/drive/MyDrive/OptionalProject/predicted_data_labelenc_notarget_randominit_small.csv\"\n",
        "nr_patients = 2"
      ],
      "metadata": {
        "id": "O1ZdEvKiCZc7"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(pred_data_path, header=[0, 1])\n",
        "gt_df = pd.read_csv(gt_test_data_path, header=[0, 1]).iloc[:, 1:]\n",
        "\n",
        "timesteps = dataset_info[dataset]['ts']\n",
        "features = dataset_info[dataset]['features']\n",
        "\n",
        "plot_predicted_vs_gt(df, gt_df, timesteps, features, nr_patients)"
      ],
      "metadata": {
        "id": "A2yB47nyIIAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_data_path = \"/content/drive/MyDrive/OptionalProject/generated_data_labelenc_notarget_randominit_small.csv\"\n",
        "nr_patients = 1\n",
        "\n",
        "df = pd.read_csv(gen_data_path, header=[0, 1])\n",
        "\n",
        "plot_generated(df, timesteps, features, nr_patients)"
      ],
      "metadata": {
        "id": "qcEmQjZx9prB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot MIMIC continuous distributions"
      ],
      "metadata": {
        "id": "EbUznxfbYls4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mimic_data_path = \"/content/drive/MyDrive/OptionalProject/MIMIC_data_labels_small.csv\"\n",
        "\n",
        "dataset = 'mimic'\n",
        "timesteps = dataset_info[dataset]['ts']\n",
        "features = dataset_info[dataset]['features']"
      ],
      "metadata": {
        "id": "n4BGwE91Y16A"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(mimic_data_path, header=[0, 1])\n",
        "\n",
        "indexes = [str(i) for i in range(0, timesteps)]\n",
        "cont_df = df.loc[:, pd.IndexSlice[indexes, :]]\n",
        "\n",
        "label = df.xs('label', level = 1, axis = 1)['-1'].values.astype(bool)\n",
        "pos_data = cont_df.loc[label].reset_index(drop=True)\n",
        "neg_data = cont_df.loc[~label].reset_index(drop=True)\n",
        "\n",
        "\n",
        "for j, f in enumerate(mimic_feats):\n",
        "    feat_data_pos = np.empty(shape=(pos_data.shape[0], timesteps))\n",
        "    feat_data_neg = np.empty(shape=(neg_data.shape[0], timesteps))\n",
        "\n",
        "    for i in range(pos_data.shape[0]):\n",
        "        feat_data_pos[i] = pos_data.xs(f, level = 1, axis = 1).loc[i].values\n",
        "    for i in range(neg_data.shape[0]):\n",
        "        feat_data_neg[i] = neg_data.xs(f, level = 1, axis = 1).loc[i].values\n",
        "\n",
        "    feat_data_mean_pos = np.nanmean(feat_data_pos, axis=0)\n",
        "    feat_data_mean_neg = np.nanmean(feat_data_neg, axis=0)\n",
        "\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax[0].plot(pd.DataFrame(feat_data_mean_pos).rolling(12).mean(), label='Smoothed positive', color='red')\n",
        "    ax[1].plot(pd.DataFrame(feat_data_mean_neg).rolling(12).mean(), label='Smoothed negative', color='red')\n",
        "    ax[0].set_title(f\"Mean {f} - positive patients across time\")\n",
        "    ax[1].set_title(f\"Mean {f} - negative patients across time\")\n",
        "    ax[0].legend()\n",
        "    ax[1].legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "bA-U7iDAY8IV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot static distributions"
      ],
      "metadata": {
        "id": "fhGh0pk3FdoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mimic_data_path = \"/content/drive/MyDrive/OptionalProject/MIMIC_data_labels_small.csv\"\n",
        "\n",
        "mimic_feats = ['Age', 'gender', 'insurance', 'ethnicity']"
      ],
      "metadata": {
        "id": "v1W2R36hFgjj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(mimic_data_path, header=[0, 1])\n",
        "\n",
        "stat_df = df.loc[:, pd.IndexSlice['-1', :]].droplevel(level=0, axis=1).iloc[:, :-1]\n",
        "\n",
        "fig, axes = plt.subplots(1, 4, figsize=(15, 4))\n",
        "\n",
        "gender_values = stat_df['gender'].value_counts()\n",
        "axes[0].bar(gender_values.index, gender_values / stat_df.shape[0] * 100)\n",
        "axes[0].set_title(\"Gender distribution in percentages\")\n",
        "axes[0].tick_params(axis='x', rotation=90)\n",
        "insurance_values = stat_df['insurance'].value_counts()\n",
        "axes[1].bar(insurance_values.index, insurance_values / stat_df.shape[0] * 100)\n",
        "axes[1].set_title(\"Insurance distribution in percentages\")\n",
        "axes[1].tick_params(axis='x', rotation=90)\n",
        "ethnicity_values = stat_df['ethnicity'].value_counts()\n",
        "axes[2].bar(['White', 'Unknown', 'Black', 'Other', 'Hispanic', 'Asian', 'Not obtained', 'Alaska native'], ethnicity_values / stat_df.shape[0] * 100)\n",
        "axes[2].set_title(\"Ethnicity distribution in percentages\")\n",
        "axes[2].tick_params(axis='x', rotation=90)\n",
        "axes[3].hist(stat_df['Age'])\n",
        "axes[3].set_title(\"Age distribution\")\n",
        "axes[3].tick_params(axis='x', rotation=90)\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('statc_feats.png')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GltLqbCDFk3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get data missingness MIMIC"
      ],
      "metadata": {
        "id": "MzUjBXB9oFwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mimic_data_path = \"/content/drive/MyDrive/OptionalProject/MIMIC_data_labels_small.csv\"\n",
        "\n",
        "dataset = 'mimic'\n",
        "\n",
        "timesteps = dataset_info[dataset]['ts']\n",
        "features = dataset_info[dataset]['features']"
      ],
      "metadata": {
        "id": "LyuDS2ZcoItA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_missing_data_perc(df, feats, timesteps):\n",
        "\n",
        "    indexes = [str(i) for i in range(0, timesteps)]\n",
        "    cont_df = df.loc[:, pd.IndexSlice[indexes, :]]\n",
        "\n",
        "    missing_data_perc = {}\n",
        "    for i, c in enumerate(feats):\n",
        "        data = cont_df.xs(c, level = 1, axis = 1)\n",
        "        miss = data.isna().sum() / data.shape[0]\n",
        "        if not missing_data_perc.get(c, None):\n",
        "            missing_data_perc[c] = [miss.values]\n",
        "        else:\n",
        "            missing_data_perc.append(miss.values)\n",
        "\n",
        "    return missing_data_perc\n",
        "\n",
        "\n",
        "def compute_missing_data_perc_class(df, feats, timesteps):\n",
        "\n",
        "    indexes = [str(i) for i in range(0, timesteps)]\n",
        "    cont_df = df.loc[:, pd.IndexSlice[indexes, :]]\n",
        "\n",
        "    label = df.xs('label', level = 1, axis = 1)['-1'].values.astype(bool)\n",
        "    pos_data = cont_df.loc[label].reset_index(drop=True)\n",
        "    neg_data = cont_df.loc[~label].reset_index(drop=True)\n",
        "\n",
        "    missing_data_perc_pos = {}\n",
        "    missing_data_perc_neg = {}\n",
        "    for i, c in enumerate(feats):\n",
        "        data_pos = pos_data.xs(c, level = 1, axis = 1)\n",
        "        data_neg = neg_data.xs(c, level = 1, axis = 1)\n",
        "        miss_pos = data_pos.isna().sum() / data_pos.shape[0]\n",
        "        miss_neg = data_neg.isna().sum() / data_neg.shape[0]\n",
        "        if not missing_data_perc_pos.get(c, None):\n",
        "            missing_data_perc_pos[c] = [miss_pos.values]\n",
        "        else:\n",
        "            missing_data_perc_pos.append(miss_pos.values)\n",
        "\n",
        "        if not missing_data_perc_neg.get(c, None):\n",
        "            missing_data_perc_neg[c] = [miss_neg.values]\n",
        "        else:\n",
        "            missing_data_perc_neg.append(miss_neg.values)\n",
        "\n",
        "    return missing_data_perc_pos, missing_data_perc_neg"
      ],
      "metadata": {
        "id": "zn1k_9d6oL0k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(mimic_data_path, header=[0, 1])\n",
        "\n",
        "missing_data_perc_pos, missing_data_perc_neg = compute_missing_data_perc_class(df, mimic_feats, timesteps)\n",
        "\n",
        "fig, axes = plt.subplots(14, 2, figsize=(15, 35))\n",
        "\n",
        "means_pos = []\n",
        "means_neg = []\n",
        "\n",
        "for i, (key, value) in enumerate(missing_data_perc_pos.items()):\n",
        "    axes[i, 0].plot(value[0])\n",
        "    mean = np.array(value[0]).mean()\n",
        "    means_pos.append(mean)\n",
        "    axes[i, 0].hlines(mean, 0, len(value[0]) - 1, label=f'Mean percentage of missing {key} - {mean:.2f}', color='red')\n",
        "    axes[i, 0].set_title(f'Percentage of missing {key} for label 1')\n",
        "    axes[i, 0].legend()\n",
        "\n",
        "for j, (key, value) in enumerate(missing_data_perc_neg.items()):\n",
        "    axes[j, 1].plot(value[0])\n",
        "    mean = np.array(value[0]).mean()\n",
        "    means_neg.append(mean)\n",
        "    axes[j, 1].hlines(mean, 0, len(value[0]) - 1, label=f'Mean percentage of missing {key} - {mean:.2f}', color='red')\n",
        "    axes[j, 1].set_title(f'Percentage of missing {key} for label 0')\n",
        "    axes[j, 1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.bar(mimic_feats, means_pos, label='Positive cases', alpha=0.5)\n",
        "plt.bar(mimic_feats, means_neg, label='Negative cases', alpha=0.5)\n",
        "plt.xticks(rotation = 90)\n",
        "plt.yticks([0.1 * x for x in range(0, 10)])\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.title(\"Average percentage of missing data across time, per feature\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UpCDYQn2t6QN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_data_perc = compute_missing_data_perc(df, mimic_feats, timesteps)\n",
        "\n",
        "for key, value in missing_data_perc.items():\n",
        "    plt.plot(value[0])\n",
        "    mean = np.array(value[0]).mean()\n",
        "    plt.hlines(mean, 0, len(value[0]) - 1, label=f'Mean percentage of missing {key} - {mean:.2f}', color='red')\n",
        "    plt.title(f'Percentage of missing {key}')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "OLFyYEg1vA3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Insert missing values in toy dataset"
      ],
      "metadata": {
        "id": "4JCZ-nuBrrP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "toy_data_path = \"/content/drive/MyDrive/OptionalProject/MIMIC_data_labels_toy.csv\"\n",
        "\n",
        "# output_toy_missing_path = \"/content/drive/MyDrive/OptionalProject/MIMIC_data_labels_toy_missing.csv\"\n",
        "# missing_data_perc = np.array([0.82, 0.88, 0.91, 0.93, 0.92, 0.91, 0.93, 0.93, 0.94, 0.93])\n",
        "\n",
        "output_toy_missing_path = \"/content/drive/MyDrive/OptionalProject/MIMIC_data_labels_toy_missing_30.csv\"\n",
        "missing_data_perc = np.array([0.22, 0.28, 0.31, 0.33, 0.32, 0.31, 0.33, 0.33, 0.34, 0.33])\n",
        "\n",
        "dataset = 'toy'\n",
        "timesteps = dataset_info[dataset]['ts']\n",
        "toy_cont_feats = dataset_info[dataset]['features']"
      ],
      "metadata": {
        "id": "SUZju4dioi0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert nan's and save dataframe\n",
        "df = pd.read_csv(toy_data_path, header=[0, 1])\n",
        "\n",
        "for c in toy_cont_feats:\n",
        "    for t in range(timesteps):\n",
        "        nr_missing_values = int(missing_data_perc[t] * df.shape[0])\n",
        "        miss_indexes = np.random.choice(df.index, nr_missing_values, replace=False)\n",
        "        df.loc[sorted(miss_indexes), (str(t), c)] = np.nan\n",
        "\n",
        "df.to_csv(output_toy_missing_path, index=False)"
      ],
      "metadata": {
        "id": "A9GfLUXMtL_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = pd.read_csv(output_toy_missing_path, header=[0, 1]).iloc[:, :-5] # don't consider static data and label\n",
        "print(f'Total features per row: {x.shape[1]}')\n",
        "print(f'Missing features per row: {x.isnull().sum(axis=1).mean()}')"
      ],
      "metadata": {
        "id": "-gAlPmDInR4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metrics and plots on generated data"
      ],
      "metadata": {
        "id": "tugAy5IXXTBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The MAE is not a good indicator and we only rely on the plots generated with below functions\n",
        "\n",
        "def generated_data_metrics(df, gt_df, timesteps, features, verbose=False):\n",
        "\n",
        "    metrics = {}\n",
        "    indexes = [str(i) for i in range(0, timesteps)]\n",
        "    label_values = ['No', 'Yes']\n",
        "    gender_values = ['M', 'F']\n",
        "    results_pos = {}\n",
        "    results_neg = {}\n",
        "\n",
        "    for j, f in enumerate(features):\n",
        "\n",
        "        if f == 'F1_constant':\n",
        "            # For each gender\n",
        "            for gender_index in range(len(gender_values)):\n",
        "                new_gt_df_gender = gt_df[(gt_df.xs('gender', level = 1, axis = 1) == gender_values[gender_index]).values].reset_index()\n",
        "                new_df_gender = df[(gt_df.xs('gender', level = 1, axis = 1) == gender_values[gender_index]).values].reset_index()\n",
        "\n",
        "                # For each label\n",
        "                for label_index in range(len(label_values)):\n",
        "                    new_gt_df = new_gt_df_gender[(new_gt_df_gender.xs('label', level = 1, axis = 1) == label_values[label_index]).values].reset_index()\n",
        "                    new_df = new_df_gender[(new_gt_df_gender.xs('label', level = 1, axis = 1) == label_values[label_index]).values].reset_index()\n",
        "\n",
        "                    cont_df = new_df.loc[:, pd.IndexSlice[indexes, :]]\n",
        "                    cont_df_gt = new_gt_df.loc[:, pd.IndexSlice[indexes, :]]\n",
        "\n",
        "                    all_data = pd.DataFrame(columns=list(range(1, timesteps)))\n",
        "                    all_data_gt = pd.DataFrame(columns=list(range(1, timesteps)))\n",
        "\n",
        "                    for i in range(new_df.shape[0]):\n",
        "\n",
        "                        y_gt = cont_df_gt.xs(f, level = 1, axis = 1).loc[i].values\n",
        "                        y_gt = np.array(y_gt)\n",
        "                        valid_idx = np.argwhere(~np.isnan(y_gt))\n",
        "\n",
        "                        pred = np.empty((y_gt.shape[0],))\n",
        "                        pred[:] = np.nan\n",
        "                        y = cont_df.xs(f, level = 1, axis = 1).loc[i].values\n",
        "                        pred[valid_idx] = y[valid_idx]\n",
        "\n",
        "                        all_data.loc[i] = pred[1:]\n",
        "                        all_data_gt.loc[i] = y_gt[1:]\n",
        "\n",
        "                    all_data_gt_mean = all_data_gt.mean()\n",
        "                    std_gt = all_data_gt.std()\n",
        "                    all_data_mean = all_data.mean()\n",
        "                    std = all_data.std()\n",
        "\n",
        "                    if verbose:\n",
        "                        for i in range(all_data_gt.shape[0]):\n",
        "                            plt.plot(all_data_gt.loc[i], color='#ABCDFF', alpha=0.4)\n",
        "\n",
        "                        plt.plot(all_data_gt_mean, label=f'Ground_truth - {label_values[label_index]} - {gender_values[gender_index]}', linewidth=3)\n",
        "\n",
        "                        for i in range(all_data.shape[0]):\n",
        "                            plt.plot(all_data.loc[i], color='#FACC8D', alpha=0.4)\n",
        "\n",
        "                        plt.plot(all_data_mean, label=f'Predicted - {label_values[label_index]} - {gender_values[gender_index]}', linewidth=3)\n",
        "\n",
        "                        plt.title(f\"Mean values of {f} across timesteps\")\n",
        "                        plt.ylim([-2.5, 2.5])\n",
        "                        plt.legend()\n",
        "                        plt.show()\n",
        "\n",
        "                    abs_dif = np.abs(all_data_gt_mean - all_data_mean)\n",
        "\n",
        "                    if label_index == 0:\n",
        "                        results_neg[f + gender_values[gender_index]] = abs_dif\n",
        "                    else:\n",
        "                        results_pos[f + gender_values[gender_index]] = abs_dif\n",
        "        else:\n",
        "             # For each label\n",
        "                for label_index in range(len(label_values)):\n",
        "                    new_gt_df = gt_df[(gt_df.xs('label', level = 1, axis = 1) == label_values[label_index]).values].reset_index()\n",
        "                    new_df = df[(gt_df.xs('label', level = 1, axis = 1) == label_values[label_index]).values].reset_index()\n",
        "\n",
        "                    cont_df = new_df.loc[:, pd.IndexSlice[indexes, :]]\n",
        "                    cont_df_gt = new_gt_df.loc[:, pd.IndexSlice[indexes, :]]\n",
        "\n",
        "                    all_data = pd.DataFrame(columns=list(range(1, timesteps)))\n",
        "                    all_data_gt = pd.DataFrame(columns=list(range(1, timesteps)))\n",
        "\n",
        "                    for i in range(new_df.shape[0]):\n",
        "\n",
        "                        y_gt = cont_df_gt.xs(f, level = 1, axis = 1).loc[i].values\n",
        "                        y_gt = np.array(y_gt)\n",
        "                        valid_idx = np.argwhere(~np.isnan(y_gt))\n",
        "\n",
        "                        pred = np.empty((y_gt.shape[0],))\n",
        "                        pred[:] = np.nan\n",
        "                        y = cont_df.xs(f, level = 1, axis = 1).loc[i].values\n",
        "                        pred[valid_idx] = y[valid_idx]\n",
        "\n",
        "                        all_data.loc[i] = pred[1:]\n",
        "                        all_data_gt.loc[i] = y_gt[1:]\n",
        "\n",
        "                    all_data_gt_mean = all_data_gt.mean()\n",
        "                    std_gt = all_data_gt.std()\n",
        "                    all_data_mean = all_data.mean()\n",
        "                    std = all_data.std()\n",
        "\n",
        "                    if verbose:\n",
        "                        for i in range(all_data_gt.shape[0]):\n",
        "                            plt.plot(all_data_gt.loc[i], color='#ABCDFF', alpha=0.4)\n",
        "\n",
        "                        plt.plot(all_data_gt_mean, label=f'Ground_truth - {label_values[label_index]}', linewidth=3)\n",
        "\n",
        "                        for i in range(all_data.shape[0]):\n",
        "                            plt.plot(all_data.loc[i], color='#FACC8D', alpha=0.4)\n",
        "\n",
        "                        plt.plot(all_data_mean, label=f'Predicted - {label_values[label_index]}', linewidth=3)\n",
        "\n",
        "                        plt.title(f\"Mean values of {f} across timesteps\")\n",
        "                        plt.ylim([-2.5, 2.5])\n",
        "                        plt.legend()\n",
        "                        plt.show()\n",
        "\n",
        "                    abs_dif = np.abs(all_data_gt_mean - all_data_mean)\n",
        "\n",
        "                    if label_index == 0:\n",
        "                        results_neg[f] = abs_dif\n",
        "                    else:\n",
        "                        results_pos[f] = abs_dif\n",
        "\n",
        "    return results_neg, results_pos"
      ],
      "metadata": {
        "id": "ZaZS3A0nXXIX"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_data_path = \"/content/drive/MyDrive/OptionalProject/generated_data_labelenc_notarget_randominit_small.csv\"\n",
        "gt_gen_data_path = \"/content/drive/MyDrive/OptionalProject/GT_generated_data_labelenc_notarget_randominit_small.csv\"\n",
        "\n",
        "dataset = 'mimic'\n",
        "timesteps = dataset_info[dataset]['ts']\n",
        "features = dataset_info[dataset]['features']\n",
        "\n",
        "df = pd.read_csv(gen_data_path, header=[0, 1])\n",
        "gt_df = pd.read_csv(gt_gen_data_path, header=[0, 1])\n",
        "\n",
        "results_neg, results_pos = generated_data_metrics(df, gt_df, timesteps, features, verbose=True)"
      ],
      "metadata": {
        "id": "ZCdM-5udXVaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HW1fyq4TQXVL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}